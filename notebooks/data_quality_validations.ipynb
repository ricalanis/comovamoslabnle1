{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1030d72e-5275-45cd-8012-6ad882604696",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "class CustomJSONizer(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        return super().encode(bool(obj)) \\\n",
    "            if isinstance(obj, np.bool_) \\\n",
    "            else super().default(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2379b70c-1722-4765-a9d5-262b06557bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime\n",
    "import re\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "class DataQualityAnalyzer:\n",
    "    def __init__(self, file_path: str):\n",
    "        \"\"\"Initialize the analyzer with a file path.\"\"\"\n",
    "        self.file_path = file_path\n",
    "        # Read file based on extension\n",
    "        if file_path.endswith('.csv'):\n",
    "            try:\n",
    "                self.df = pd.read_csv(file_path)\n",
    "            except:\n",
    "                self.df = pd.read_csv(file_path, encoding=\"latin-1\")\n",
    "            \n",
    "        elif file_path.endswith(('.xlsx', '.xls')):\n",
    "            try:\n",
    "                self.df = pd.read_excel(file_path)\n",
    "            except:\n",
    "                self.df = pd.read_excel(file_path, encoding=\"latin-1\")\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported file format. Please use CSV or Excel files.\")\n",
    "        \n",
    "        self.total_rows = len(self.df)\n",
    "        self.total_columns = len(self.df.columns)\n",
    "        self.columns = list(self.df.columns)\n",
    "\n",
    "    def analyze_completeness(self) -> Dict[str, Any]:\n",
    "        \"\"\"Analyze data completeness.\"\"\"\n",
    "        total_cells = self.total_rows * self.total_columns\n",
    "        total_null_cells = self.df.isna().sum().sum()\n",
    "        null_counts = self.df.isna().sum().to_dict()\n",
    "        \n",
    "        completeness_ratio = 1 - (total_null_cells / total_cells)\n",
    "        \n",
    "        validations = {}\n",
    "        for col in self.columns:\n",
    "            unexpected_count = self.df[col].isna().sum()\n",
    "            unexpected_percent = (unexpected_count / self.total_rows) * 100\n",
    "            validations[col] = {\n",
    "                \"success\": unexpected_count == 0,\n",
    "                \"unexpected_count\": int(unexpected_count),\n",
    "                \"unexpected_percent\": round(unexpected_percent, 3)\n",
    "            }\n",
    "        \n",
    "        return {\n",
    "            \"metrics\": {\n",
    "                \"total_rows\": self.total_rows,\n",
    "                \"total_cells\": total_cells,\n",
    "                \"total_null_cells\": int(total_null_cells),\n",
    "                \"completeness_ratio\": round(completeness_ratio, 3),\n",
    "                \"null_counts_by_column\": null_counts\n",
    "            },\n",
    "            \"validations\": validations,\n",
    "            \"grade\": self._calculate_grade(completeness_ratio)\n",
    "        }\n",
    "\n",
    "    def analyze_accuracy(self) -> Dict[str, Any]:\n",
    "        \"\"\"Analyze data accuracy.\"\"\"\n",
    "        metrics = {}\n",
    "        for col in self.columns:\n",
    "            col_metrics = {}\n",
    "            col_metrics[\"data_type\"] = str(self.df[col].dtype)\n",
    "            col_metrics[\"unique_values_count\"] = self.df[col].nunique()\n",
    "            \n",
    "            if pd.api.types.is_numeric_dtype(self.df[col]):\n",
    "                col_metrics.update({\n",
    "                    \"min\": float(self.df[col].min()),\n",
    "                    \"max\": float(self.df[col].max()),\n",
    "                    \"mean\": round(float(self.df[col].mean()), 3),\n",
    "                    \"std\": round(float(self.df[col].std()), 3)\n",
    "                })\n",
    "            elif pd.api.types.is_string_dtype(self.df[col]):\n",
    "                if \"email\" in col.lower():\n",
    "                    email_pattern = r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$'\n",
    "                    pattern_matches = self.df[col].str.match(email_pattern, na=False)\n",
    "                    col_metrics[\"pattern_match_rate\"] = round(pattern_matches.mean(), 3)\n",
    "            \n",
    "            metrics[col] = col_metrics\n",
    "        \n",
    "        # Simplified accuracy score based on data type consistency\n",
    "        accuracy_score = 1.0\n",
    "        for col in self.columns:\n",
    "            if self.df[col].dtype == 'object':\n",
    "                # Penalize for mixed data types in string columns\n",
    "                unique_types = self.df[col].apply(type).nunique()\n",
    "                if unique_types > 1:\n",
    "                    accuracy_score -= 0.05\n",
    "        \n",
    "        return {\n",
    "            \"metrics\": metrics,\n",
    "            \"validations\": {\n",
    "                \"data_type_check\": {\n",
    "                    \"success\": accuracy_score > 0.95,\n",
    "                    \"unexpected_count\": int((1 - accuracy_score) * self.total_rows)\n",
    "                }\n",
    "            },\n",
    "            \"grade\": self._calculate_grade(accuracy_score)\n",
    "        }\n",
    "\n",
    "    def analyze_consistency(self) -> Dict[str, Any]:\n",
    "        \"\"\"Analyze data consistency.\"\"\"\n",
    "        metrics = {}\n",
    "        for col in self.columns:\n",
    "            if pd.api.types.is_string_dtype(self.df[col]):\n",
    "                value_counts = self.df[col].value_counts()\n",
    "                metrics[col] = {\n",
    "                    \"unique_values_count\": len(value_counts),\n",
    "                    \"most_common_value\": value_counts.index[0],\n",
    "                    \"most_common_value_frequency\": int(value_counts.iloc[0]),\n",
    "                    \"value_distribution\": value_counts.to_dict(),\n",
    "                    \"length_stats\": {\n",
    "                        \"min_length\": int(self.df[col].str.len().min()),\n",
    "                        \"max_length\": int(self.df[col].str.len().max()),\n",
    "                        \"mean_length\": round(float(self.df[col].str.len().mean()), 1)\n",
    "                    }\n",
    "                }\n",
    "        \n",
    "        # Calculate consistency score based on value distributions\n",
    "        consistency_score = 1.0\n",
    "        for col in metrics:\n",
    "            unique_ratio = metrics[col][\"unique_values_count\"] / self.total_rows\n",
    "            if unique_ratio > 0.9 and \"id\" not in col.lower() and \"email\" not in col.lower():\n",
    "                consistency_score -= 0.1\n",
    "        \n",
    "        return {\n",
    "            \"metrics\": metrics,\n",
    "            \"validations\": {\n",
    "                \"value_set_check\": {\n",
    "                    \"success\": consistency_score > 0.9,\n",
    "                    \"unexpected_count\": int((1 - consistency_score) * self.total_rows)\n",
    "                }\n",
    "            },\n",
    "            \"grade\": self._calculate_grade(consistency_score)\n",
    "        }\n",
    "\n",
    "    def analyze_uniqueness(self) -> Dict[str, Any]:\n",
    "        \"\"\"Analyze data uniqueness.\"\"\"\n",
    "        metrics = {}\n",
    "        for col in self.columns:\n",
    "            duplicate_counts = self.df[col].value_counts()\n",
    "            duplicates = duplicate_counts[duplicate_counts > 1].to_dict()\n",
    "            metrics[col] = {\n",
    "                \"unique_count\": self.df[col].nunique(),\n",
    "                \"duplicate_count\": len(duplicates),\n",
    "                \"duplication_ratio\": round(len(duplicates) / self.total_rows, 3),\n",
    "                \"duplicate_values\": duplicates\n",
    "            }\n",
    "        \n",
    "        return {\n",
    "            \"metrics\": metrics,\n",
    "            \"validations\": {\n",
    "                f\"{col}_uniqueness\": {\n",
    "                    \"success\": metrics[col][\"duplicate_count\"] == 0,\n",
    "                    \"unexpected_count\": metrics[col][\"duplicate_count\"],\n",
    "                    \"unexpected_percent\": round(metrics[col][\"duplication_ratio\"] * 100, 3)\n",
    "                } for col in self.columns\n",
    "            },\n",
    "            \"grade\": self._calculate_grade(1 - max(m[\"duplication_ratio\"] for m in metrics.values()))\n",
    "        }\n",
    "\n",
    "    def _calculate_grade(self, score: float) -> Dict[str, Any]:\n",
    "        \"\"\"Calculate grade based on score.\"\"\"\n",
    "        score = round(score, 3)\n",
    "        if score >= 0.95:\n",
    "            interpretation = \"Excellent\"\n",
    "        elif score >= 0.90:\n",
    "            interpretation = \"Good\"\n",
    "        elif score >= 0.85:\n",
    "            interpretation = \"Fair\"\n",
    "        elif score >= 0.80:\n",
    "            interpretation = \"Poor\"\n",
    "        else:\n",
    "            interpretation = \"Failed\"\n",
    "        \n",
    "        return {\n",
    "            \"score\": score,\n",
    "            \"interpretation\": interpretation,\n",
    "            \"threshold_met\": score >= 0.85\n",
    "        }\n",
    "\n",
    "    def generate_report(self) -> Dict[str, Any]:\n",
    "        \"\"\"Generate complete data quality report.\"\"\"\n",
    "        completeness = self.analyze_completeness()\n",
    "        accuracy = self.analyze_accuracy()\n",
    "        consistency = self.analyze_consistency()\n",
    "        uniqueness = self.analyze_uniqueness()\n",
    "        \n",
    "        category_scores = {\n",
    "            \"completeness\": completeness[\"grade\"][\"score\"],\n",
    "            \"accuracy\": accuracy[\"grade\"][\"score\"],\n",
    "            \"consistency\": consistency[\"grade\"][\"score\"],\n",
    "            \"uniqueness\": uniqueness[\"grade\"][\"score\"]\n",
    "        }\n",
    "        \n",
    "        overall_score = round(np.mean(list(category_scores.values())), 3)\n",
    "        \n",
    "        recommendations = []\n",
    "        if completeness[\"grade\"][\"score\"] < 0.98:\n",
    "            recommendations.append({\n",
    "                \"category\": \"completeness\",\n",
    "                \"issue\": \"Missing values detected\",\n",
    "                \"impact\": \"Medium\",\n",
    "                \"suggestion\": \"Review and fill in missing data where possible\"\n",
    "            })\n",
    "        \n",
    "        if uniqueness[\"grade\"][\"score\"] < 0.98:\n",
    "            recommendations.append({\n",
    "                \"category\": \"uniqueness\",\n",
    "                \"issue\": \"Duplicate values found\",\n",
    "                \"impact\": \"High\",\n",
    "                \"suggestion\": \"Investigate and resolve duplicate records\"\n",
    "            })\n",
    "        \n",
    "        return {\n",
    "            \"metadata\": {\n",
    "                \"filename\": self.file_path,\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "                \"total_rows\": self.total_rows,\n",
    "                \"total_columns\": self.total_columns,\n",
    "                \"columns\": self.columns,\n",
    "                \"analysis_version\": \"1.0\"\n",
    "            },\n",
    "            \"quality_checks\": {\n",
    "                \"completeness\": completeness,\n",
    "                \"accuracy\": accuracy,\n",
    "                \"consistency\": consistency,\n",
    "                \"uniqueness\": uniqueness\n",
    "            },\n",
    "            \"overall_quality\": {\n",
    "                \"score\": overall_score,\n",
    "                \"grade\": self._calculate_grade(overall_score)[\"interpretation\"],\n",
    "                \"interpretation\": self._calculate_grade(overall_score)[\"interpretation\"],\n",
    "                \"category_scores\": category_scores,\n",
    "                \"recommendations\": recommendations\n",
    "            },\n",
    "            \"thresholds\": {\n",
    "                \"grades\": {\n",
    "                    \"A\": {\"min\": 0.95, \"interpretation\": \"Excellent\"},\n",
    "                    \"B\": {\"min\": 0.90, \"interpretation\": \"Good\"},\n",
    "                    \"C\": {\"min\": 0.85, \"interpretation\": \"Fair\"},\n",
    "                    \"D\": {\"min\": 0.80, \"interpretation\": \"Poor\"},\n",
    "                    \"F\": {\"min\": 0.00, \"interpretation\": \"Failed\"}\n",
    "                },\n",
    "                \"critical_checks\": {\n",
    "                    \"null_tolerance\": [\"id\", \"email\"],\n",
    "                    \"uniqueness_required\": [\"id\", \"email\"],\n",
    "                    \"format_validation\": [\"email\", \"signup_date\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1971cf46-5f80-444d-875a-daa7e15b6dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize analyzer with your data file\n",
    "analyzer = DataQualityAnalyzer(\"personal_dependencias_2022_2023_2024 (1).csv\")\n",
    "\n",
    "# Generate report\n",
    "report = analyzer.generate_report()\n",
    "\n",
    "# Save report to JSON file\n",
    "with open(\"data_quality_report.json\", \"w\") as f:\n",
    "    json.dump(report, f, indent=2, cls=CustomJSONizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
